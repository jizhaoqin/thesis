{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f70138-0361-4984-a38e-5d820cfb1e3d",
   "metadata": {},
   "source": [
    "# Trial DESI trained neural network\n",
    "## 1. Extract Data from DESI data release\n",
    "- refer to `intro_to_DESI_EDR_files.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2a04a5-5129-44a3-87e8-5d2e80b607c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import some helpful python packages \n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.convolution import convolve, Gaussian1DKernel\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('./others/desi.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9c418c-3fe6-47a8-be4d-72c6745e8903",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import DESI related modules - \n",
    "from desimodel.footprint import radec2pix      # For getting healpix values\n",
    "import desispec.io                             # Input/Output functions related to DESI spectra\n",
    "from desispec import coaddition                # Functions related to coadding the spectra\n",
    "\n",
    "# DESI targeting masks - \n",
    "from desitarget.sv1 import sv1_targetmask    # For SV1\n",
    "from desitarget.sv2 import sv2_targetmask    # For SV2\n",
    "from desitarget.sv3 import sv3_targetmask    # For SV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd786872-7681-4bca-9abb-b0b88474a478",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/desi/spectro/redux/iron\n"
     ]
    }
   ],
   "source": [
    "# Release directory path\n",
    "\n",
    "specprod = 'iron'    # Internal name for the EDR\n",
    "specprod_dir = '/global/cfs/cdirs/desi/spectro/redux/' + specprod\n",
    "print(specprod_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936defac-5fc2-48ac-a616-9f3e576692da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zpix_cat_is_galaxy = np.load(\"./saves/zpix_cat_is_galaxy.npy\")\n",
    "zpix_cat = Table.read(f'{specprod_dir}/zcatalog/zall-pix-{specprod}.fits', hdu=\"ZCATALOG\")[zpix_cat_is_galaxy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c672fb-9e46-42f7-be8c-0f23dbb21986",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'astropy.table.table.Table'> 21696490\n"
     ]
    }
   ],
   "source": [
    "print(type(zpix_cat), len(zpix_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "581a4504-de51-4f93-8d79-df9eacae1cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=5</i>\n",
       "<table id=\"table140622672105424\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>TARGETID</th><th>SURVEY</th><th>PROGRAM</th><th>HEALPIX</th><th>SPGRPVAL</th><th>Z</th><th>ZERR</th><th>ZWARN</th><th>CHI2</th><th>COEFF</th><th>NPIXELS</th><th>SPECTYPE</th><th>SUBTYPE</th><th>NCOEFF</th><th>DELTACHI2</th><th>COADD_FIBERSTATUS</th><th>TARGET_RA</th><th>TARGET_DEC</th><th>PMRA</th><th>PMDEC</th><th>REF_EPOCH</th><th>FA_TARGET</th><th>FA_TYPE</th><th>OBJTYPE</th><th>SUBPRIORITY</th><th>OBSCONDITIONS</th><th>RELEASE</th><th>BRICKNAME</th><th>BRICKID</th><th>BRICK_OBJID</th><th>MORPHTYPE</th><th>EBV</th><th>FLUX_G</th><th>FLUX_R</th><th>FLUX_Z</th><th>FLUX_W1</th><th>FLUX_W2</th><th>FLUX_IVAR_G</th><th>FLUX_IVAR_R</th><th>FLUX_IVAR_Z</th><th>FLUX_IVAR_W1</th><th>FLUX_IVAR_W2</th><th>FIBERFLUX_G</th><th>FIBERFLUX_R</th><th>FIBERFLUX_Z</th><th>FIBERTOTFLUX_G</th><th>FIBERTOTFLUX_R</th><th>FIBERTOTFLUX_Z</th><th>MASKBITS</th><th>SERSIC</th><th>SHAPE_R</th><th>SHAPE_E1</th><th>SHAPE_E2</th><th>REF_ID</th><th>REF_CAT</th><th>GAIA_PHOT_G_MEAN_MAG</th><th>GAIA_PHOT_BP_MEAN_MAG</th><th>GAIA_PHOT_RP_MEAN_MAG</th><th>PARALLAX</th><th>PHOTSYS</th><th>PRIORITY_INIT</th><th>NUMOBS_INIT</th><th>CMX_TARGET</th><th>DESI_TARGET</th><th>BGS_TARGET</th><th>MWS_TARGET</th><th>SCND_TARGET</th><th>SV1_DESI_TARGET</th><th>SV1_BGS_TARGET</th><th>SV1_MWS_TARGET</th><th>SV1_SCND_TARGET</th><th>SV2_DESI_TARGET</th><th>SV2_BGS_TARGET</th><th>SV2_MWS_TARGET</th><th>SV2_SCND_TARGET</th><th>SV3_DESI_TARGET</th><th>SV3_BGS_TARGET</th><th>SV3_MWS_TARGET</th><th>SV3_SCND_TARGET</th><th>PLATE_RA</th><th>PLATE_DEC</th><th>COADD_NUMEXP</th><th>COADD_EXPTIME</th><th>COADD_NUMNIGHT</th><th>COADD_NUMTILE</th><th>MEAN_DELTA_X</th><th>RMS_DELTA_X</th><th>MEAN_DELTA_Y</th><th>RMS_DELTA_Y</th><th>MEAN_FIBER_RA</th><th>STD_FIBER_RA</th><th>MEAN_FIBER_DEC</th><th>STD_FIBER_DEC</th><th>MEAN_PSF_TO_FIBER_SPECFLUX</th><th>TSNR2_GPBDARK_B</th><th>TSNR2_ELG_B</th><th>TSNR2_GPBBRIGHT_B</th><th>TSNR2_LYA_B</th><th>TSNR2_BGS_B</th><th>TSNR2_GPBBACKUP_B</th><th>TSNR2_QSO_B</th><th>TSNR2_LRG_B</th><th>TSNR2_GPBDARK_R</th><th>TSNR2_ELG_R</th><th>TSNR2_GPBBRIGHT_R</th><th>TSNR2_LYA_R</th><th>TSNR2_BGS_R</th><th>TSNR2_GPBBACKUP_R</th><th>TSNR2_QSO_R</th><th>TSNR2_LRG_R</th><th>TSNR2_GPBDARK_Z</th><th>TSNR2_ELG_Z</th><th>TSNR2_GPBBRIGHT_Z</th><th>TSNR2_LYA_Z</th><th>TSNR2_BGS_Z</th><th>TSNR2_GPBBACKUP_Z</th><th>TSNR2_QSO_Z</th><th>TSNR2_LRG_Z</th><th>TSNR2_GPBDARK</th><th>TSNR2_ELG</th><th>TSNR2_GPBBRIGHT</th><th>TSNR2_LYA</th><th>TSNR2_BGS</th><th>TSNR2_GPBBACKUP</th><th>TSNR2_QSO</th><th>TSNR2_LRG</th><th>MAIN_NSPEC</th><th>MAIN_PRIMARY</th><th>SV_NSPEC</th><th>SV_PRIMARY</th><th>ZCAT_NSPEC</th><th>ZCAT_PRIMARY</th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>bytes7</th><th>bytes6</th><th>int32</th><th>int32</th><th>float64</th><th>float64</th><th>int64</th><th>float64</th><th>float64[10]</th><th>int64</th><th>bytes6</th><th>bytes20</th><th>int64</th><th>float64</th><th>int32</th><th>float64</th><th>float64</th><th>float32</th><th>float32</th><th>float32</th><th>int64</th><th>uint8</th><th>bytes3</th><th>float64</th><th>int32</th><th>int16</th><th>bytes8</th><th>int32</th><th>int32</th><th>bytes4</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>int16</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>int64</th><th>bytes2</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>bytes1</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th><th>float64</th><th>float64</th><th>int16</th><th>float32</th><th>int16</th><th>int16</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float64</th><th>float32</th><th>float64</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>int32</th><th>bool</th><th>int32</th><th>bool</th><th>int64</th><th>bool</th></tr></thead>\n",
       "<tr><td>39628483705438705</td><td>cmx</td><td>other</td><td>2153</td><td>2153</td><td>0.9549765465799412</td><td>6.337646627836233e-05</td><td>0</td><td>8277.82517927885</td><td>25.182798895163756 .. 2.449810721298287</td><td>7928</td><td>GALAXY</td><td>--</td><td>10</td><td>14.312310665845871</td><td>0</td><td>24.583503066002486</td><td>30.216567171317408</td><td>0.0</td><td>0.0</td><td>2020.9597</td><td>2048</td><td>1</td><td>TGT</td><td>0.9827835723915774</td><td>3</td><td>9010</td><td>0247p302</td><td>497017</td><td>497</td><td>REX</td><td>0.046512615</td><td>0.2737542</td><td>0.3430835</td><td>0.2783253</td><td>1.9005281</td><td>1.0421883</td><td>2061.1145</td><td>471.4325</td><td>62.777065</td><td>3.3555176</td><td>0.73318565</td><td>0.14113112</td><td>0.1768731</td><td>0.14348768</td><td>0.14117967</td><td>0.17693171</td><td>0.14355366</td><td>0</td><td>1.0</td><td>0.49542147</td><td>0.0</td><td>0.0</td><td>0</td><td>--</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>S</td><td>3000</td><td>1</td><td>2048</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>24.583503066002486</td><td>30.216567171317408</td><td>4</td><td>3600.0</td><td>1</td><td>1</td><td>0.00525</td><td>0.008760707</td><td>0.00075</td><td>0.004769696</td><td>24.583478955370396</td><td>0.13638209</td><td>30.216569814697692</td><td>0.06616776</td><td>0.76944447</td><td>542.6087</td><td>0.4709213</td><td>100.765854</td><td>439.72195</td><td>2308.856</td><td>681.3403</td><td>12.753676</td><td>3.945053</td><td>37538.395</td><td>81.67198</td><td>6661.2754</td><td>0.18977702</td><td>7619.6934</td><td>40402.59</td><td>24.900114</td><td>117.4269</td><td>5.9244776e-05</td><td>303.3242</td><td>1.1048722e-05</td><td>0.0</td><td>12617.437</td><td>7.5980206e-05</td><td>61.369797</td><td>134.76157</td><td>38081.004</td><td>385.4671</td><td>6762.041</td><td>439.91174</td><td>22545.984</td><td>41083.93</td><td>99.02359</td><td>256.1335</td><td>0</td><td>False</td><td>0</td><td>False</td><td>1</td><td>True</td></tr>\n",
       "<tr><td>39628483701249266</td><td>cmx</td><td>other</td><td>2153</td><td>2153</td><td>0.9122369740101364</td><td>0.0002123473731260472</td><td>0</td><td>8758.555644992739</td><td>54.49493300752991 .. 3.040363332377466</td><td>7928</td><td>GALAXY</td><td>--</td><td>10</td><td>166.5843929760158</td><td>0</td><td>24.53251052236921</td><td>30.197231711858777</td><td>0.0</td><td>0.0</td><td>2020.9597</td><td>2048</td><td>1</td><td>TGT</td><td>0.9040460585375006</td><td>3</td><td>9010</td><td>0244p302</td><td>497016</td><td>5362</td><td>REX</td><td>0.047126617</td><td>0.4060862</td><td>0.8378453</td><td>2.7442741</td><td>9.807552</td><td>6.666676</td><td>621.8876</td><td>199.89471</td><td>20.723118</td><td>2.8979256</td><td>0.68580663</td><td>0.1537954</td><td>0.31731382</td><td>1.039328</td><td>0.15379566</td><td>0.31731454</td><td>1.0393325</td><td>0</td><td>1.0</td><td>0.74291134</td><td>0.0</td><td>0.0</td><td>0</td><td>--</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>S</td><td>3000</td><td>1</td><td>2048</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>24.53251052236921</td><td>30.197231711858777</td><td>4</td><td>3600.0</td><td>1</td><td>1</td><td>0.00375</td><td>0.007053368</td><td>-0.0025</td><td>0.005</td><td>24.532493007316297</td><td>0.116333865</td><td>30.197221971875873</td><td>0.060646076</td><td>0.75882584</td><td>489.52963</td><td>0.42781433</td><td>91.140045</td><td>400.69818</td><td>2103.175</td><td>623.69525</td><td>11.615481</td><td>3.5744662</td><td>35055.68</td><td>76.47339</td><td>6230.1064</td><td>0.17641726</td><td>7105.2236</td><td>38093.586</td><td>23.315447</td><td>109.80748</td><td>5.611017e-05</td><td>286.96964</td><td>1.0477452e-05</td><td>0.0</td><td>11933.254</td><td>7.262718e-05</td><td>58.150017</td><td>127.36008</td><td>35545.21</td><td>363.87085</td><td>6321.2466</td><td>400.8746</td><td>21141.652</td><td>38717.28</td><td>93.08095</td><td>240.74202</td><td>0</td><td>False</td><td>0</td><td>False</td><td>1</td><td>True</td></tr>\n",
       "<tr><td>39628483705440516</td><td>cmx</td><td>other</td><td>2153</td><td>2153</td><td>0.5523515369528929</td><td>1.1002414956197951e-06</td><td>0</td><td>15212.64501953125</td><td>246.23372812182905 .. -14.177052410218682</td><td>7928</td><td>GALAXY</td><td>--</td><td>10</td><td>120530.73322296143</td><td>0</td><td>24.681756453908598</td><td>30.35761664452527</td><td>0.0</td><td>0.0</td><td>2020.9597</td><td>36028797018968064</td><td>1</td><td>TGT</td><td>0.259630378567685</td><td>7</td><td>9010</td><td>0247p302</td><td>497017</td><td>2308</td><td>PSF</td><td>0.046624493</td><td>1.7112678</td><td>2.5731533</td><td>2.3794425</td><td>9.441193</td><td>20.3394</td><td>942.6277</td><td>260.7799</td><td>40.30578</td><td>3.188242</td><td>0.6917823</td><td>1.3327067</td><td>2.0039287</td><td>1.8530699</td><td>1.3327067</td><td>2.0039287</td><td>1.8530699</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>--</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>S</td><td>3400</td><td>1</td><td>36028797018968064</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>24.681756453908598</td><td>30.35761664452527</td><td>4</td><td>3600.0</td><td>1</td><td>1</td><td>0.0035</td><td>0.0055677644</td><td>-0.003</td><td>0.0035355338</td><td>24.68173997589153</td><td>0.082922995</td><td>30.357604812822352</td><td>0.025805095</td><td>0.789</td><td>520.5887</td><td>0.37932727</td><td>96.81095</td><td>289.0088</td><td>1991.287</td><td>671.9463</td><td>10.197584</td><td>3.812738</td><td>38155.734</td><td>84.7787</td><td>6776.477</td><td>0.1922295</td><td>7662.279</td><td>42038.83</td><td>25.607819</td><td>120.53768</td><td>6.368398e-05</td><td>311.54083</td><td>1.1846729e-05</td><td>0.0</td><td>13103.11</td><td>8.2662045e-05</td><td>63.787136</td><td>138.97253</td><td>38676.324</td><td>396.69885</td><td>6873.288</td><td>289.20102</td><td>22756.676</td><td>42710.773</td><td>99.592545</td><td>263.32294</td><td>0</td><td>False</td><td>0</td><td>False</td><td>2</td><td>True</td></tr>\n",
       "<tr><td>616089241234964843</td><td>cmx</td><td>other</td><td>2153</td><td>2153</td><td>0.932752477574551</td><td>2.232146096148817e-46</td><td>519</td><td>9.000000000000002e+99</td><td>0.0 .. 0.0</td><td>0</td><td>GALAXY</td><td>--</td><td>10</td><td>0.0</td><td>512</td><td>24.774719360827007</td><td>30.451198618850484</td><td>0.0</td><td>0.0</td><td>0.0</td><td>4294967296</td><td>4</td><td>SKY</td><td>0.9985601934567682</td><td>63</td><td>9010</td><td>0247p305</td><td>498263</td><td>363</td><td>--</td><td>0.05223905</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.009525567</td><td>-0.005927755</td><td>0.03759135</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>--</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>--</td><td>-1</td><td>-1</td><td>4294967296</td><td>4294967296</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>24.774719360827007</td><td>30.451198618850484</td><td>0</td><td>0.0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>24.774719360827</td><td>0.0</td><td>30.451198618850498</td><td>0.0</td><td>0.79036385</td><td>403.01196</td><td>0.2936096</td><td>74.652664</td><td>226.46931</td><td>1543.0046</td><td>548.83136</td><td>8.054763</td><td>2.9468231</td><td>30647.582</td><td>68.139366</td><td>5425.91</td><td>0.15740857</td><td>6120.605</td><td>35578.652</td><td>21.012077</td><td>96.16447</td><td>5.1967127e-05</td><td>254.73347</td><td>9.607358e-06</td><td>0.0</td><td>10713.21</td><td>7.052646e-05</td><td>53.38695</td><td>113.1652</td><td>31050.594</td><td>323.16644</td><td>5500.563</td><td>226.62672</td><td>18376.82</td><td>36127.484</td><td>82.4538</td><td>212.27649</td><td>0</td><td>False</td><td>0</td><td>False</td><td>1</td><td>True</td></tr>\n",
       "<tr><td>39628483705440434</td><td>cmx</td><td>other</td><td>2153</td><td>2153</td><td>0.2888847661877839</td><td>7.83513818147459e-05</td><td>4</td><td>8683.654407080263</td><td>7.595722946895678 .. -0.9218795682464365</td><td>7928</td><td>GALAXY</td><td>--</td><td>10</td><td>5.059906933456659</td><td>0</td><td>24.67746783368929</td><td>30.335151532387563</td><td>0.0</td><td>0.0</td><td>2020.9597</td><td>2048</td><td>1</td><td>TGT</td><td>0.8709354893059359</td><td>3</td><td>9010</td><td>0247p302</td><td>497017</td><td>2226</td><td>PSF</td><td>0.045590498</td><td>0.27525312</td><td>0.26038677</td><td>0.5035696</td><td>0.09540175</td><td>5.1039367</td><td>2439.9775</td><td>622.9312</td><td>64.016464</td><td>3.3915884</td><td>0.7444912</td><td>0.21399611</td><td>0.20243824</td><td>0.39150125</td><td>0.21405712</td><td>0.20250997</td><td>0.39161864</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>--</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>S</td><td>3000</td><td>1</td><td>2048</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>24.67746783368929</td><td>30.335151532387563</td><td>4</td><td>3600.0</td><td>1</td><td>1</td><td>0.00125</td><td>0.0040926766</td><td>-0.00325</td><td>0.0042130747</td><td>24.67746172120114</td><td>0.07472323</td><td>30.335138852024826</td><td>0.037340038</td><td>0.789</td><td>497.3344</td><td>0.35752708</td><td>92.708084</td><td>269.42096</td><td>1890.4734</td><td>647.3471</td><td>9.604626</td><td>3.614011</td><td>36530.05</td><td>81.09669</td><td>6503.726</td><td>0.18437743</td><td>7370.127</td><td>40553.75</td><td>24.519749</td><td>115.338776</td><td>6.131522e-05</td><td>303.15295</td><td>1.1424892e-05</td><td>0.0</td><td>12747.478</td><td>8.0033875e-05</td><td>62.03047</td><td>135.12991</td><td>37027.387</td><td>384.60718</td><td>6596.434</td><td>269.60535</td><td>22008.078</td><td>41201.098</td><td>96.15485</td><td>254.0827</td><td>0</td><td>False</td><td>0</td><td>False</td><td>1</td><td>True</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "     TARGETID      SURVEY PROGRAM HEALPIX ... SV_PRIMARY ZCAT_NSPEC ZCAT_PRIMARY\n",
       "      int64        bytes7  bytes6  int32  ...    bool      int64        bool    \n",
       "------------------ ------ ------- ------- ... ---------- ---------- ------------\n",
       " 39628483705438705    cmx   other    2153 ...      False          1         True\n",
       " 39628483701249266    cmx   other    2153 ...      False          1         True\n",
       " 39628483705440516    cmx   other    2153 ...      False          2         True\n",
       "616089241234964843    cmx   other    2153 ...      False          1         True\n",
       " 39628483705440434    cmx   other    2153 ...      False          1         True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zpix_cat[50:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b16f357e-49ac-4306-9d74-dca220dd93d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selecting All galaxy targets\n",
    "is_galaxy = zpix_cat[\"SPECTYPE\"] == \"GALAXY\"\n",
    "# np.save(\"./saves/zpix_cat_is_galaxy\", is_galaxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2831b2f1-fd9b-4dd9-9e8d-3d6d2239e954",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> 21696490 21696490\n"
     ]
    }
   ],
   "source": [
    "print(type(is_galaxy), len(is_galaxy), len(zpix_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25add905-937d-48dd-869d-0424960e59fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dc3add1-3ce0-4f61-8cd4-19e346ed33d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# flag of confidence -> Δχ^2>40 or not\n",
    "is_confident = zpix_cat[\"DELTACHI2\"] > 40\n",
    "# not_confident = zpix_cat[\"DELTACHI2\"] < 40\n",
    "# not_confident = ~is_confident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e0f450c-c8f5-4c9b-957d-a3f6590c667e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.96060556 0.         ... 0.25930887 0.34113547 0.        ] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(zpix_cat[\"SHAPE_R\"].data, type(is_confident.astype(int)))\n",
    "# zpix_cat[\"SHAPE_R\"].data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7491c1e-8598-438f-ac92-ff109551958a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Transfer data to DataLoader for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70b44df3-2d56-474e-b3c9-173fe3827771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb708082-9759-49ea-bed8-091904418c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_in_data = np.stack((zpix_cat[\"SHAPE_R\"].data.astype(np.float32), zpix_cat[\"GAIA_PHOT_G_MEAN_MAG\"].data.astype(np.float32)), axis=-1)\n",
    "np_out_data = is_confident.astype(np.intp)\n",
    "dataset = TensorDataset(\n",
    "    torch.as_tensor(np_in_data),\n",
    "    torch.as_tensor(np_out_data),\n",
    ")\n",
    "# np_in_data.shape, np_out_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e67afd81-677f-4883-ba83-2da62813d88a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "837"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbb2d727-f798-45ec-9e44-da4009011482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use random_split to create the splits\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37ac7513-c309-49cd-934b-87c1a4f0e32f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'> 2713 173632 17357192.0\n",
      "info of input data: <class 'torch.Tensor'>, torch.Size([6400, 2]), torch.float32\n",
      "info of output flag: <class 'torch.Tensor'>, torch.Size([6400]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 6400\n",
    "# construct instances for class `DataLoader`, with parameters \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# `DataLoader` instances are iterable, but not subscpriptable\n",
    "print(type(train_dataloader), len(train_dataloader), len(train_dataloader)*64, len(zpix_cat)*0.8)\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(f\"info of input data: {type(X)}, {X.shape}, {X.dtype}\")\n",
    "    print(f\"info of output flag: {type(y)}, {y.shape} {y.dtype}\")\n",
    "    break  # only show index 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50005eaa-4ccb-4a58-bd0e-61ce5761c95c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Define neural network and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f281b6f-be32-4f17-a2bb-68d6c4981ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.1)\n",
      "    (2): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.1)\n",
      "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=2, out_features=16),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(in_features=16, out_features=32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(in_features=32, out_features=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65ff9314-2745-4187-ae86-93b439b4b57f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To train a model, also need a loss function and an optimizer (besides dataset and neural network)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4eda6eb-5b47-46f6-9f79-93065ebf0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a single training loop, the model makes predictions on the training dataset (fed to it in batches),\n",
    "# and backpropagates the prediction error to adjust the model’s parameters.\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    model.train() # default is true, means training, false means evaluation mode\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # clear gradients for the optimizer, for next time optimization\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to predict the output with current network\n",
    "        pred = model(X)\n",
    "        \n",
    "        # Compute the loss, output is torch.Tensor\n",
    "        loss = loss_fn(pred.squeeze(), y.squeeze())\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights of the network\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            print(f\"{type(loss):}\")\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "# check the model’s performance against the test dataset to ensure it is learning.\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "032604e9-b244-4d62-9571-813a8ebf32f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [11,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [12,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [15,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [18,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [20,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [21,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [22,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [24,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [25,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [26,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [27,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [28,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [29,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [31,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     test(test_dataloader, model, loss_fn)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[45], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# update the weights of the network\u001b[39;00m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:260\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    251\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    252\u001b[0m     (inputs,)\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[1;32m    257\u001b[0m )\n\u001b[1;32m    259\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m--> 260\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:143\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    137\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         )\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    142\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 143\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     )\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142b9a7-326d-44e7-96a6-3c0222dfcd36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESI main",
   "language": "python",
   "name": "desi-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
