{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Algorithms : Part 2\n",
    "\n",
    "**WARNING**: this notebook takes considerably more time and memory than most tutorials here,\n",
    "and is probably best studied during a time other than a DESI collaboration\n",
    "meeting tutorial session.\n",
    "\n",
    "In the first part of this study we looked at simulated targets with realistic uniform densities and no physical clustering.  We gave those simulated targets realistic priorities and requested observations, and used a realistic focalplane model with accurate positioner motions and exclusion zones.  We also studied just a single pointing on the sky with one or more coincident tiles and this allowed us to Monte Carlo over the simulated targets to see the spread of the assignment fractions.\n",
    "\n",
    "This second part of the study starts with a cutout of DR8 data and uses that for a study of fiber assignment with multiple passes.  Some things to keep in mind when working with real targets:\n",
    "\n",
    "1.  Clustering effects will reduce assignment efficiency compared to the study in Part 1, due to an increase in positioner collisions.\n",
    "\n",
    "2.  Recall that when computing the \"total priority\" of targets with the same `PRIORITY` value, targets with more remaining observations will be attempted first (see https://github.com/desihub/fiberassign/issues/196).  This means that \"4 pass QSOs\" will have their assignment attempted first until their remaining requested observations equals \"1\", at which point their total priority relative to the other \"1 pass QSOs\" will be based on the random `SUBPRIORITY` value.  Obviously all QSOs will be attempted before the other lower priority target classes.\n",
    "\n",
    "3.  Real targets include some complications like targets that are marked as both science targets and standards.  These targets are assigned as science targets, but that assignment counts towards the standards budget.  Even after such a target has zero remaining observations, it can still be assigned as a standard.\n",
    "\n",
    "*This notebook was motivated by a study done by Claire Lamman.  It has been expanded to illustrate more of the details.*\n",
    "\n",
    "## Fiber Assignment vs. Survey Planning\n",
    "\n",
    "Fiberassign by itself is a toolkit for taking an input set of tiles and an input set of MTL catalogs and producing the \"best possible\" assignment of those tiles given the physical hardware and the pre-determined priorities and requested observations of the input targets.\n",
    "\n",
    "The overall assignment efficiency for the entire survey depends greatly on how exactly you choose to run fiberassign on different sets of tiles and how you update the target files in between those runs.  For the real survey, we will have a feedback loop at some cadence going like this:\n",
    "```\n",
    "Targeting ---> make_mtl() ---> MTL ---> Fiberassign ---> Observations ---> Spectro Pipeline\n",
    "                                ^                                                 |\n",
    "                                |                                                 V\n",
    "                                +--<-<-<-<-<-<-<-<-<-<-<-<-<-<-<-<-<-<-<-<-<-<-<--+\n",
    "```\n",
    "Any time an \"assignment efficiency\" is quoted for the survey, it must also include information about how this loop was operated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Definitions\n",
    "\n",
    "These are global imports and variables used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from numpy.lib.recfunctions import append_fields\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "import fitsio\n",
    "\n",
    "from desimodel.io import findfile as dm_findfile\n",
    "from desimodel.io import load_tiles as dm_load_tiles\n",
    "\n",
    "from desitarget.targetmask import desi_mask, obsconditions\n",
    "\n",
    "from desitarget.mtl import make_mtl\n",
    "\n",
    "\n",
    "from fiberassign import __version__ as fba_version\n",
    "\n",
    "from fiberassign.hardware import (\n",
    "    load_hardware,\n",
    ")\n",
    "\n",
    "from fiberassign.targets import (\n",
    "    Targets,\n",
    "    TargetTree,\n",
    "    TargetsAvailable,\n",
    "    LocationsAvailable,\n",
    "    load_target_table,\n",
    "    default_target_masks,\n",
    "    TARGET_TYPE_SCIENCE, \n",
    "    TARGET_TYPE_SKY,\n",
    "    TARGET_TYPE_SUPPSKY,\n",
    "    TARGET_TYPE_STANDARD\n",
    ")\n",
    "\n",
    "from fiberassign.tiles import (\n",
    "    load_tiles,\n",
    ")\n",
    "\n",
    "from fiberassign.assign import (\n",
    "    Assignment,\n",
    ")\n",
    "\n",
    "from fiberassign.vis import (\n",
    "    plot_assignment_tile,\n",
    ")\n",
    "\n",
    "from fiberassign.qa import qa_targets\n",
    "\n",
    "from fiberassign.scripts.assign import (\n",
    "    parse_assign,\n",
    "    run_assign_full\n",
    ")\n",
    "\n",
    "from fiberassign.scripts.merge import (\n",
    "    parse_merge,\n",
    "    run_merge\n",
    ")\n",
    "\n",
    "\n",
    "# Capture C++ output in the jupyter cells.\n",
    "#\n",
    "# If you want to see the (often very long) output from the underlying calls to fiberassign, then\n",
    "# uncomment this line (and make sure you have the wurlitzer package installed).\n",
    "#%reload_ext wurlitzer\n",
    "\n",
    "\n",
    "#---- Global parameters -----\n",
    "\n",
    "# Target RA/DEC range\n",
    "target_ra_min = 158.0\n",
    "target_ra_max = 202.0\n",
    "target_dec_min = -2.0\n",
    "target_dec_max = 32.0\n",
    "\n",
    "# Date used for the focalplane model\n",
    "assign_date = \"2020-01-01T00:00:00\"\n",
    "\n",
    "# Plotting color\n",
    "target_pltcolor = {\n",
    "    \"ELG\": (0.12156862745098039, 0.4666666666666667, 0.7058823529411765),\n",
    "    \"LRG\": (1.0, 0.4980392156862745, 0.054901960784313725),\n",
    "    \"QSO\": (0.17254901960784313, 0.6274509803921569, 0.17254901960784313),\n",
    "    \"QSO-tracer\": (0.17254901960784313, 0.6274509803921569, 0.17254901960784313),\n",
    "    \"QSO-lyman\": (0.8392156862745098, 0.15294117647058825, 0.1568627450980392),\n",
    "    \"STD\": (1.0, 0.832, 0.0),\n",
    "    \"SKY\": (0.0, 1.0, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Location\n",
    "\n",
    "Define the working directories for inputs and outputs, as well as global definitions for the cuts, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory (where input and output files will be written).  Change this to wherever you like.\n",
    "workdir = os.path.join(os.environ[\"HOME\"], \"scratch\", \"desi\", \"tutorials\", \"fiberassign_part2\")\n",
    "# workdir = os.path.join(os.environ[\"SCRATCH\"], \"desi\", \"tutorials\", \"fiberassign_part2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science / standard target sample\n",
    "target_sample = os.path.join(workdir, \"target_science_sample.fits\")\n",
    "\n",
    "# Sky target sample\n",
    "target_sample_sky = os.path.join(workdir, \"target_sky_sample.fits\")\n",
    "\n",
    "# MTL files for fiberassign\n",
    "science_file_root = \"mtl_science\"\n",
    "science_file = os.path.join(workdir, \"{}.fits\".format(science_file_root))\n",
    "std_file = os.path.join(workdir, \"mtl_std.fits\")\n",
    "sky_file = os.path.join(workdir, \"mtl_sky.fits\")\n",
    "\n",
    "# Footprint\n",
    "tilefile_root = \"footprint\"\n",
    "tilefile_pass = dict()\n",
    "\n",
    "# Output root directory name for fiberassign\n",
    "fba_root = \"fiberassign\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Selection\n",
    "\n",
    "Here we grab all targets within an RA / DEC range.  We write this code to a separate python script that can be run outside of this notebook, which is useful if the notebook is running on a laptop or workstation instead of NERSC.  \n",
    "After running this next cell, copy the generated `select_targets.py` script and run it at NERSC with the default DESI software stack.  Then copy the output FITS files into your working directory (which you defined in the previous cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile select_targets.py\n",
    "\n",
    "# Run this script at NERSC with any of the DESI software stacks.  This script only uses fitsio\n",
    "# and built-in packages.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import fitsio\n",
    "\n",
    "target_ra_min = 158.0\n",
    "target_ra_max = 202.0\n",
    "target_dec_min = -2.0\n",
    "target_dec_max = 32.0\n",
    "\n",
    "# First select the science targets\n",
    "\n",
    "# (Change this if you have the DR8 data locally)\n",
    "input_dir = \"/global/cfs/cdirs/desi/target/catalogs/dr8/0.31.1/targets/main/resolve\"\n",
    "\n",
    "input_files = glob.glob(os.path.join(input_dir, \"*.fits\"))\n",
    "\n",
    "target_data = []\n",
    "\n",
    "for file in input_files:\n",
    "    print(\"Working on {}\".format(os.path.basename(file)), flush=True)\n",
    "    fd = fitsio.FITS(file, \"r\")\n",
    "    fdata = fd[1].read()\n",
    "    inside = np.where(\n",
    "        np.logical_and(\n",
    "            np.logical_and((fdata[\"RA\"] > target_ra_min), (fdata[\"RA\"] < target_ra_max)),\n",
    "            np.logical_and((fdata[\"DEC\"] > target_dec_min), (fdata[\"DEC\"] < target_dec_max))\n",
    "        )\n",
    "    )[0]\n",
    "    target_data.append(fdata[inside])\n",
    "    fd.close()\n",
    "\n",
    "target_data = np.concatenate(target_data)\n",
    "\n",
    "out_file = \"target_science_sample.fits\" \n",
    "if os.path.isfile(out_file):\n",
    "    os.remove(out_file)\n",
    "\n",
    "fd = fitsio.FITS(out_file, \"rw\")\n",
    "fd.write(None, header=None, extname=\"PRIMARY\")\n",
    "fd.write(target_data, header=None, extname=\"TARGETS\")\n",
    "fd.close()\n",
    "\n",
    "# Now select the sky targets\n",
    "\n",
    "print(\"Working on sky...\", flush=True)\n",
    "\n",
    "sky_file = \"/global/cfs/cdirs/desi/target/catalogs/dr8/0.31.0/skies/skies-dr8-0.31.0.fits\"\n",
    "\n",
    "out_file = \"target_sky_sample.fits\" \n",
    "if os.path.isfile(out_file):\n",
    "    os.remove(out_file)\n",
    "\n",
    "fd = fitsio.FITS(sky_file, \"r\")\n",
    "fdata = fd[1].read()\n",
    "inside = np.where(\n",
    "    np.logical_and(\n",
    "        np.logical_and((fdata[\"RA\"] > target_ra_min), (fdata[\"RA\"] < target_ra_max)),\n",
    "        np.logical_and((fdata[\"DEC\"] > target_dec_min), (fdata[\"DEC\"] < target_dec_max))\n",
    "    )\n",
    ")[0]\n",
    "\n",
    "outfd = fitsio.FITS(out_file, \"rw\")\n",
    "outfd.write(None, header=None, extname=\"PRIMARY\")\n",
    "outfd.write(fdata[inside], header=None, extname=\"TARGETS\")\n",
    "outfd.close()\n",
    "\n",
    "fd.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the rest of this notebook uses the target files generated by the previous script (`target_science_sample.fits` and `target_sky_sample.fits`), which it assumes you have placed in the working directory..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(target_sample) or not os.path.isfile(target_sample_sky):\n",
    "    message = f'run select_targets.py script and copy outputs to {workdir} before proceeding'\n",
    "    raise RuntimeError(message)\n",
    "else:\n",
    "    print('target sample files generated; ok to proceed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Footprint\n",
    "\n",
    "We take the default DESI footprint and cut out the tiles that fall fully within our RA/DEC limits (up to some buffer) and which have DARK obsconditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint_file = dm_findfile(\"footprint/desi-tiles.fits\")\n",
    "footprint_data = dm_load_tiles(tilesfile=footprint_file, cache=False)\n",
    "\n",
    "tile_radius = 1.65 # degrees\n",
    "tile_cut = 2.0 # degrees\n",
    "\n",
    "tile_ra_min = target_ra_min + tile_cut\n",
    "tile_ra_max = target_ra_max - tile_cut\n",
    "tile_dec_min = target_dec_min + tile_cut\n",
    "tile_dec_max = target_dec_max - tile_cut\n",
    "\n",
    "obskeep = obsconditions['DARK']\n",
    "\n",
    "inside = np.where(\n",
    "    np.logical_and(\n",
    "        np.logical_and(\n",
    "            np.logical_and(\n",
    "                (footprint_data[\"RA\"] > tile_ra_min), \n",
    "                (footprint_data[\"RA\"] < tile_ra_max)\n",
    "            ), np.logical_and(\n",
    "                (footprint_data[\"DEC\"] > tile_dec_min), \n",
    "                (footprint_data[\"DEC\"] < tile_dec_max)\n",
    "            )\n",
    "        ),\n",
    "        (footprint_data[\"OBSCONDITIONS\"] & obskeep)\n",
    "    )\n",
    ")[0]\n",
    "\n",
    "tiledata = footprint_data[inside]\n",
    "\n",
    "# For each pass, write out a tile file.  Also write out the file for all passes.\n",
    "\n",
    "passes = np.unique(tiledata[\"PASS\"])\n",
    "\n",
    "def plot_tiles(tdata, ps, outfile):\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    ra_width = target_ra_max - target_ra_min\n",
    "    ra_center = target_ra_min + 0.5 * ra_width\n",
    "    dec_width = target_dec_max - target_dec_min\n",
    "    dec_center = target_dec_min + 0.5 * dec_width\n",
    "\n",
    "    radec_box = plt.Rectangle((target_ra_min, target_dec_min), ra_width, dec_width,\n",
    "                            angle=0.0, color=\"green\", linewidth=2.0, fill=False)\n",
    "    ax.add_artist(radec_box)\n",
    "\n",
    "    for tile in tdata:\n",
    "        clr = \"red\"\n",
    "        if tile[\"OBSCONDITIONS\"] & obsconditions[\"GRAY\"]:\n",
    "            clr = \"cyan\"\n",
    "        outline = plt.Circle(\n",
    "            (tile[\"RA\"], tile[\"DEC\"]), radius=tile_radius, fc=\"none\", ec=clr\n",
    "        )\n",
    "        ax.add_artist(outline)\n",
    "\n",
    "    ax.set_xlabel(\"RA\", fontsize=\"large\")\n",
    "    ax.set_ylabel(\"DEC\", fontsize=\"large\")\n",
    "    ax.set_xlim([target_ra_min - 1.0, target_ra_max + 1.0])\n",
    "    ax.set_ylim([target_dec_min - 1.0, target_dec_max + 1.0])\n",
    "    ax.set_title(\n",
    "        \"Tile Selection for pass \\\"{}\\\"\".format(ps)\n",
    "    )\n",
    "    plt.savefig(outfile, dpi=300, format=\"pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "print(\"Full footprint has {} tiles\".format(len(tiledata)))\n",
    "\n",
    "tilefile_pass[\"ALL\"] = os.path.join(workdir, \"{}_ALL.fits\".format(tilefile_root))\n",
    "if os.path.isfile(tilefile_pass[\"ALL\"]):\n",
    "    os.remove(tilefile_pass[\"ALL\"])\n",
    "\n",
    "outfd = fitsio.FITS(tilefile_pass[\"ALL\"], \"rw\")\n",
    "outfd.write(None, header=None, extname=\"PRIMARY\")\n",
    "outfd.write(tiledata, header=None, extname=\"TILES\")\n",
    "outfd.close()\n",
    "\n",
    "out_pdf = os.path.join(workdir, \"{}_ALL.pdf\".format(tilefile_root))\n",
    "plot_tiles(tiledata, \"ALL\", out_pdf)\n",
    "\n",
    "for ps in passes:\n",
    "    pstr = \"{}\".format(ps)\n",
    "    ps_rows = np.where(tiledata[\"PASS\"] == ps)[0]\n",
    "    tiledata_pass = tiledata[ps_rows]\n",
    "    print(\"Pass {} footprint has {} tiles\".format(ps, len(tiledata_pass)))\n",
    "    tilefile_pass[pstr] = os.path.join(workdir, \"{}_{}.fits\".format(tilefile_root, ps))\n",
    "    if os.path.isfile(tilefile_pass[pstr]):\n",
    "        os.remove(tilefile_pass[pstr])\n",
    "    outfd = fitsio.FITS(tilefile_pass[pstr], \"rw\")\n",
    "    outfd.write(None, header=None, extname=\"PRIMARY\")\n",
    "    outfd.write(tiledata_pass, header=None, extname=\"TILES\")\n",
    "    outfd.close()\n",
    "    out_pdf = os.path.join(workdir, \"{}_{}.pdf\".format(tilefile_root, ps))\n",
    "    plot_tiles(tiledata_pass, ps, out_pdf)\n",
    "\n",
    "pstr = \"2-4\"\n",
    "ps_rows = np.where(tiledata[\"PASS\"] > 1)[0]\n",
    "tiledata_pass = tiledata[ps_rows]\n",
    "print(\"Pass 2-4 footprint has {} tiles\".format(len(tiledata_pass)))\n",
    "tilefile_pass[pstr] = os.path.join(workdir, \"{}_2-4.fits\".format(tilefile_root))\n",
    "if os.path.isfile(tilefile_pass[pstr]):\n",
    "    os.remove(tilefile_pass[pstr])\n",
    "outfd = fitsio.FITS(tilefile_pass[pstr], \"rw\")\n",
    "outfd.write(None, header=None, extname=\"PRIMARY\")\n",
    "outfd.write(tiledata_pass, header=None, extname=\"TILES\")\n",
    "outfd.close()\n",
    "out_pdf = os.path.join(workdir, \"{}_{}.pdf\".format(tilefile_root, pstr))\n",
    "plot_tiles(tiledata_pass, pstr, out_pdf)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with MTL files\n",
    "\n",
    "For this exercise we are assigning just the 4 passes of DARK tiles.  We select out only the ELG, LRG and QSO science targets, and also keep targets marked as specific standards (STD_FAINT, STD_WD, STD_BRIGHT).  If there are any targets that have bits for multiple target classes set, we cut those.  In order to avoid confusion, we also remove targets marked as both a standard and a science target.\n",
    "\n",
    "We will be generating the initial MTL file using the `desitarget.mtl.make_mtl()` function.  We update the MTL file with a small helper function in between runs of fiber assignment.\n",
    "\n",
    "To make things simpler, we keep only the input target columns needed for assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw science / standard target sample and prune columns\n",
    "\n",
    "keep_columns = [\n",
    "    'TARGETID', \n",
    "    'RA', \n",
    "    'DEC',\n",
    "    'RA_IVAR',\n",
    "    'DEC_IVAR',\n",
    "    'PMRA',\n",
    "    'PMDEC',\n",
    "    'PMRA_IVAR',\n",
    "    'PMDEC_IVAR',\n",
    "    'DESI_TARGET', \n",
    "    'BGS_TARGET', \n",
    "    'MWS_TARGET', \n",
    "    'SUBPRIORITY', \n",
    "    'BRICKNAME',\n",
    "    'BRICKID',\n",
    "    'BRICK_OBJID',\n",
    "    'PRIORITY_INIT', \n",
    "    'NUMOBS_INIT'\n",
    "]\n",
    "\n",
    "fd = fitsio.FITS(target_sample)\n",
    "targets_raw = fd[1].read(columns=keep_columns)\n",
    "\n",
    "# Get the default target masks for this target file\n",
    "\n",
    "(filesurvey, \n",
    " filecol, \n",
    " def_sciencemask, \n",
    " def_stdmask, \n",
    " def_skymask, \n",
    " def_suppskymask,\n",
    " def_safemask, \n",
    " def_excludemask) = default_target_masks(targets_raw)\n",
    "\n",
    "print(\"Detected targets for survey '{}', using bitfield column '{}'\".format(filesurvey, filecol))\n",
    "\n",
    "# Force our science and std masks to a more restrictive set.  Only keep ELG, LRG and QSO targets.\n",
    "# Cut any targets with multiple of those set.\n",
    "\n",
    "science_mask = 0\n",
    "science_mask |= desi_mask[\"LRG\"].mask\n",
    "science_mask |= desi_mask[\"ELG\"].mask\n",
    "science_mask |= desi_mask[\"QSO\"].mask\n",
    "\n",
    "std_mask = 0\n",
    "std_mask |= desi_mask[\"STD_FAINT\"].mask\n",
    "std_mask |= desi_mask[\"STD_WD\"].mask\n",
    "std_mask |= desi_mask[\"STD_BRIGHT\"].mask\n",
    "\n",
    "elg_rows = np.where(\n",
    "    np.logical_and(\n",
    "        np.logical_and(\n",
    "            np.logical_and(\n",
    "                np.bitwise_and(targets_raw[\"DESI_TARGET\"], desi_mask[\"ELG\"].mask),\n",
    "                np.logical_not(\n",
    "                    np.bitwise_and(targets_raw[\"DESI_TARGET\"], std_mask)\n",
    "                )\n",
    "            ),\n",
    "            np.logical_not(\n",
    "                np.bitwise_and(targets_raw[\"DESI_TARGET\"], desi_mask[\"QSO\"].mask)\n",
    "            )\n",
    "        ),\n",
    "        np.logical_not(\n",
    "            np.bitwise_and(targets_raw[\"DESI_TARGET\"], desi_mask[\"LRG\"].mask)\n",
    "        )\n",
    "    )\n",
    ")[0]\n",
    "\n",
    "qso_rows = np.where(\n",
    "    np.logical_and(\n",
    "        np.logical_and(\n",
    "            np.logical_and(\n",
    "                np.bitwise_and(targets_raw[\"DESI_TARGET\"], desi_mask[\"QSO\"].mask),\n",
    "                np.logical_not(\n",
    "                    np.bitwise_and(targets_raw[\"DESI_TARGET\"], std_mask)\n",
    "                )\n",
    "            ),\n",
    "            np.logical_not(\n",
    "                np.bitwise_and(targets_raw[\"DESI_TARGET\"], desi_mask[\"ELG\"].mask)\n",
    "            )\n",
    "        ),\n",
    "        np.logical_not(\n",
    "            np.bitwise_and(targets_raw[\"DESI_TARGET\"], desi_mask[\"LRG\"].mask)\n",
    "        )\n",
    "    )\n",
    ")[0]\n",
    "\n",
    "lrg_rows = np.where(\n",
    "    np.logical_and(\n",
    "        np.logical_and(\n",
    "            np.logical_and(\n",
    "                np.bitwise_and(targets_raw[\"DESI_TARGET\"], desi_mask[\"LRG\"].mask),\n",
    "                np.logical_not(\n",
    "                    np.bitwise_and(targets_raw[\"DESI_TARGET\"], std_mask)\n",
    "                )\n",
    "            ),\n",
    "            np.logical_not(\n",
    "                np.bitwise_and(targets_raw[\"DESI_TARGET\"], desi_mask[\"QSO\"].mask)\n",
    "            )\n",
    "        ),\n",
    "        np.logical_not(\n",
    "            np.bitwise_and(targets_raw[\"DESI_TARGET\"], desi_mask[\"ELG\"].mask)\n",
    "        )\n",
    "    )\n",
    ")[0]\n",
    "\n",
    "n_elg = len(elg_rows)\n",
    "n_qso = len(qso_rows)\n",
    "n_lrg = len(lrg_rows)\n",
    "\n",
    "science_rows = np.concatenate([elg_rows, qso_rows, lrg_rows])\n",
    "\n",
    "std_rows = np.where(\n",
    "    np.logical_and(\n",
    "        np.bitwise_and(targets_raw[\"DESI_TARGET\"], std_mask),\n",
    "        np.logical_not(\n",
    "            np.bitwise_and(targets_raw[\"DESI_TARGET\"], science_mask)\n",
    "        )\n",
    "    )\n",
    ")[0]\n",
    "\n",
    "print(\n",
    "    \"Using {} science and {} standards from input catalog\".format(\n",
    "        len(science_rows),\n",
    "        len(std_rows)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Split out the science and standard targets, although this is actually not necessary for passing\n",
    "# to fiberassign.\n",
    "\n",
    "science_targets = np.array(targets_raw[science_rows])\n",
    "\n",
    "std_targets = np.array(targets_raw[std_rows])\n",
    "\n",
    "# Close the input fits file so it doesn't take up extra memory\n",
    "del targets_raw\n",
    "fd.close()\n",
    "del fd\n",
    "\n",
    "# We have concatenated the 3 target types in the new table, so now the rows are\n",
    "# different:\n",
    "elg_rows = np.arange(n_elg, dtype=np.int64)\n",
    "qso_rows = np.arange(n_qso, dtype=np.int64) + n_elg\n",
    "lrg_rows = np.arange(n_lrg, dtype=np.int64) + n_elg + n_qso\n",
    "\n",
    "# Make the MTLs\n",
    "\n",
    "science_mtl = make_mtl(science_targets, \"DARK|GRAY\").as_array()\n",
    "if len(science_mtl) != len(science_targets):\n",
    "    print(\"WARNING:  science MTL has {} rows, input has {}\".format(len(science_mtl), len(science_targets)))\n",
    "\n",
    "std_mtl = make_mtl(std_targets, \"DARK|GRAY\").as_array()\n",
    "if len(std_mtl) != len(std_targets):\n",
    "    print(\"WARNING:  standards MTL has {} rows, input has {}\".format(len(std_mtl), len(std_targets)))\n",
    "\n",
    "# Delete the large intermediate arrays\n",
    "    \n",
    "del science_targets\n",
    "del std_targets\n",
    "    \n",
    "# Write MTLs\n",
    "\n",
    "if os.path.isfile(science_file):\n",
    "    os.remove(science_file)\n",
    "with fitsio.FITS(science_file, \"rw\") as fd:\n",
    "    fd.write(science_mtl)\n",
    "\n",
    "if os.path.isfile(std_file):\n",
    "    os.remove(std_file)\n",
    "with fitsio.FITS(std_file, \"rw\") as fd:\n",
    "    fd.write(std_mtl)    \n",
    "\n",
    "print(\"{} science targets\".format(len(science_mtl)))\n",
    "print(\"    {} ELG targets\".format(len(elg_rows)))\n",
    "print(\"    {} QSO targets\".format(len(qso_rows)))\n",
    "print(\"    {} LRG targets\".format(len(lrg_rows)))\n",
    "print(\"{} std targets\".format(len(std_mtl)))\n",
    "\n",
    "# We'll be loading later science MTLs as we go through the survey, so delete that now.\n",
    "# the standards are constant so we'll keep those in memory.\n",
    "\n",
    "del science_mtl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the skies file.\n",
    "\n",
    "keep_columns = [\n",
    "    'TARGETID', \n",
    "    'RA', \n",
    "    'DEC', \n",
    "    'DESI_TARGET', \n",
    "    'BGS_TARGET', \n",
    "    'MWS_TARGET', \n",
    "    'SUBPRIORITY', \n",
    "    'BRICKNAME',\n",
    "    'BRICKID',\n",
    "    'BRICK_OBJID',\n",
    "    'APFLUX_G',\n",
    "    'APFLUX_R',\n",
    "    'APFLUX_Z',\n",
    "    'APFLUX_IVAR_G',\n",
    "    'APFLUX_IVAR_R',\n",
    "    'APFLUX_IVAR_Z',\n",
    "    'OBSCONDITIONS'\n",
    "]\n",
    "\n",
    "fd = fitsio.FITS(target_sample_sky)\n",
    "sky_mtl = np.array(fd[1].read(columns=keep_columns))\n",
    "fd.close()\n",
    "del fd\n",
    "\n",
    "# Sanity check that these are all sky, supp_sky, or bad_sky\n",
    "\n",
    "print(\"{} input targets in sky file\".format(len(sky_mtl)))\n",
    "\n",
    "sky_sky_rows = np.where(\n",
    "    np.bitwise_and(sky_mtl[\"DESI_TARGET\"], desi_mask[\"SKY\"].mask)\n",
    ")[0]\n",
    "\n",
    "print(\"  {} SKY targets\".format(len(sky_sky_rows)))\n",
    "\n",
    "sky_suppsky_rows = np.where(\n",
    "    np.bitwise_and(sky_mtl[\"DESI_TARGET\"], desi_mask[\"SUPP_SKY\"].mask)\n",
    ")[0]\n",
    "\n",
    "print(\"  {} SUPP_SKY targets\".format(len(sky_suppsky_rows)))\n",
    "\n",
    "sky_badsky_rows = np.where(\n",
    "    np.bitwise_and(sky_mtl[\"DESI_TARGET\"], desi_mask[\"BAD_SKY\"].mask)\n",
    ")[0]\n",
    "\n",
    "print(\"  {} BAD_SKY targets\".format(len(sky_badsky_rows)))\n",
    "\n",
    "sky_mask = 0\n",
    "sky_mask |= desi_mask[\"SKY\"].mask\n",
    "sky_mask |= desi_mask[\"SUPP_SKY\"].mask\n",
    "sky_mask |= desi_mask[\"BAD_SKY\"].mask\n",
    "\n",
    "sky_unknown_rows = np.where(\n",
    "    np.logical_not(\n",
    "        np.bitwise_and(sky_mtl[\"DESI_TARGET\"], sky_mask)\n",
    "    )\n",
    ")[0]\n",
    "\n",
    "print(\"  {} targets are not one of the 3 recognized types\".format(len(sky_unknown_rows)))\n",
    "\n",
    "if os.path.isfile(sky_file):\n",
    "    os.remove(sky_file)\n",
    "with fitsio.FITS(sky_file, \"rw\") as fd:\n",
    "    fd.write(sky_mtl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Now that we have our starting footprint of tiles and our input MTL catalogs, we'll define some functions for use later in this notebook.  These include some convenience wrappers for running the main fiberassign high-level function, for accumulating assignment totals and available / considered targets for a given run, and for updating the MTLs with observation counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update the MTL obs remaining.\n",
    "\n",
    "def update_mtl(science_input, science_output, obs):\n",
    "    \"\"\"\n",
    "    This takes the input MTL and sets the NUMOBS_MORE column based on the\n",
    "    input dictionary of obs remaining for each target.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"  Loading data from {}\".format(science_input), flush=True)\n",
    "    tdata = None\n",
    "    with fitsio.FITS(science_input) as fd:\n",
    "        tdata = fd[1].read()\n",
    "    \n",
    "    if \"NUMOBS_MORE\" not in tdata.dtype.names:\n",
    "        # create this column based on NUMOBS_INIT\n",
    "        tdata = append_fields(tdata, \"NUMOBS_MORE\", tdata[\"NUMOBS_INIT\"])\n",
    "        \n",
    "    # Sanity check\n",
    "    \n",
    "    if len(obs) != len(tdata):\n",
    "        msg = \"The length of the MTL table ({}) does not match the obs dict ({})\".format(\n",
    "            len(tdata), len(obs)\n",
    "        )\n",
    "        raise RuntimeError(msg)\n",
    "        \n",
    "    # Now assign the new obs remaining data\n",
    "    \n",
    "    print(\"  Updating observation counts\", flush=True)\n",
    "    tdata[\"NUMOBS_MORE\"][:] = [obs[x] for x in tdata[\"TARGETID\"]]\n",
    "    \n",
    "    if os.path.isfile(science_output):\n",
    "        os.remove(science_output)\n",
    "        \n",
    "    print(\"  Writing updated MTL to {}\".format(science_output), flush=True)\n",
    "    with fitsio.FITS(science_output, \"rw\") as fd:\n",
    "        fd.write(tdata)\n",
    "\n",
    "    del tdata\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the observation count difference between 2 MTLs\n",
    "\n",
    "def diff_mtl(start_mtl, final_mtl, qso_lyman_rows, qso_tracer_rows):\n",
    "    keep_columns = [\n",
    "        \"TARGETID\",\n",
    "        \"DESI_TARGET\",\n",
    "        \"NUMOBS_INIT\"\n",
    "    ]\n",
    "    print(\"  Loading data from {}\".format(start_mtl), flush=True)\n",
    "    start_data = None\n",
    "    with fitsio.FITS(start_mtl) as fd:\n",
    "        start_data = fd[1].read(columns=keep_columns)\n",
    "    \n",
    "    keep_columns = [\n",
    "        \"TARGETID\",\n",
    "        \"DESI_TARGET\",\n",
    "        \"NUMOBS_MORE\"\n",
    "    ]\n",
    "    print(\"  Loading data from {}\".format(final_mtl), flush=True)\n",
    "    final_data = None\n",
    "    with fitsio.FITS(final_mtl) as fd:\n",
    "        final_data = fd[1].read(columns=keep_columns)\n",
    "    \n",
    "    counts = dict()\n",
    "    \n",
    "    for tgclass, rows in zip(\n",
    "        [\"ELG\", \"LRG\", \"QSO-lyman\", \"QSO-tracer\"],\n",
    "        [elg_rows, lrg_rows, qso_lyman_rows, qso_tracer_rows]\n",
    "    ):\n",
    "        counts[tgclass] = dict()\n",
    "        counts[tgclass][\"requested\"] = np.sum(start_data[\"NUMOBS_INIT\"][rows])\n",
    "        counts[tgclass][\"achieved\"] = np.sum(\n",
    "            start_data[\"NUMOBS_INIT\"][rows] - final_data[\"NUMOBS_MORE\"][rows]\n",
    "        )\n",
    "    \n",
    "    del start_data\n",
    "    del final_data\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the fba_run and fba_merge commandline entrypoints\n",
    "\n",
    "def run_assignment(footprint, outdir, science):\n",
    "    opts = [\n",
    "        \"--rundate\", assign_date,\n",
    "        \"--overwrite\",\n",
    "        \"--write_all_targets\",\n",
    "        \"--footprint\", footprint,\n",
    "        \"--dir\", outdir,\n",
    "        \"--targets\", science, std_file, sky_file\n",
    "    ]\n",
    "    print(\"  Running raw fiber assignment (fba_run)...\")\n",
    "    print(\"    (Uncomment the 'wurlitzer' line at the top of the notebook to see the output here)\")\n",
    "    ag = parse_assign(opts)\n",
    "    run_assign_full(ag)\n",
    "    \n",
    "    opts = [\n",
    "        \"--skip_raw\",\n",
    "        \"--dir\", outdir,\n",
    "        \"--targets\", science, std_file, sky_file\n",
    "    ]\n",
    "    print(\"  Merging input target data (fba_merge_results)...\")\n",
    "    print(\"    (Uncomment the 'wurlitzer' line at the top of the notebook to see the output here)\")\n",
    "    ag = parse_merge(opts)\n",
    "    run_merge(ag)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the assigned, available, and considered targets for a set of tiles\n",
    "\n",
    "def assignment_counts(footprint, science_input, fba_dir, qso_lyman_rows, qso_tracer_rows):\n",
    "    # Load the footprint\n",
    "    tile_data = None\n",
    "    with fitsio.FITS(footprint) as fd:\n",
    "        tile_data = np.array(fd[1].read())\n",
    "    \n",
    "    # Load the input science MTL and get the obs remaining for all targets\n",
    "    mtldata = None\n",
    "    with fitsio.FITS(science_input) as fd:\n",
    "        mtldata = fd[1].read()\n",
    "\n",
    "    obs = None\n",
    "    if \"NUMOBS_MORE\" in mtldata.dtype.names:\n",
    "        obs = {\n",
    "            x: y for x, y in zip(mtldata[\"TARGETID\"], mtldata[\"NUMOBS_MORE\"])\n",
    "        }\n",
    "    else:\n",
    "        obs = {\n",
    "            x: y for x, y in zip(mtldata[\"TARGETID\"], mtldata[\"NUMOBS_INIT\"])\n",
    "        }\n",
    "    qso_lyman = mtldata[\"TARGETID\"][qso_lyman_rows]\n",
    "    qso_tracer = mtldata[\"TARGETID\"][qso_tracer_rows]\n",
    "\n",
    "    class_masks = {\n",
    "        \"ELG\": desi_mask[\"ELG\"].mask,\n",
    "        \"LRG\": desi_mask[\"LRG\"].mask,\n",
    "        \"QSO-lyman\": desi_mask[\"QSO\"].mask,\n",
    "        \"QSO-tracer\": desi_mask[\"QSO\"].mask,\n",
    "        \"STD\": std_mask,\n",
    "        \"SKY\": sky_mask\n",
    "    }\n",
    "    \n",
    "    # histogram data to return\n",
    "    hist_tgassign = dict()\n",
    "    hist_tgavail = dict()\n",
    "    hist_tgconsid = dict()\n",
    "    hist_tgfrac = dict()\n",
    "    for tgclass, mask in class_masks.items():\n",
    "        hist_tgassign[tgclass] = list()\n",
    "        hist_tgavail[tgclass] = list()\n",
    "        hist_tgconsid[tgclass] = list()\n",
    "        hist_tgfrac[tgclass] = list()\n",
    "    \n",
    "    print(\"  Accumulating assignment counts for {} tiles...\".format(len(tile_data)), flush=True)\n",
    "    \n",
    "    for tl in tile_data[\"TILEID\"]:\n",
    "        # For each tile in order of assignment...\n",
    "        \n",
    "        # Load assignment and available targets and their properties.\n",
    "        # NOTE: because we used the --write_all_targets option to fba_run, we get the properties\n",
    "        # of all available targets in the FTARGETS HDU and have access to those here.\n",
    "        \n",
    "        fba_file = os.path.join(fba_dir, \"fiberassign-{:06d}.fits\".format(tl))\n",
    "        fassign = None\n",
    "        ftarget = None\n",
    "        favail = None\n",
    "        with fitsio.FITS(fba_file, \"r\") as fd:\n",
    "            fassign = fd[\"FIBERASSIGN\"].read()\n",
    "            ftarget = fd[\"TARGETS\"].read()\n",
    "            favail = fd[\"POTENTIAL_ASSIGNMENTS\"].read()\n",
    "        \n",
    "        # The assigned target IDs\n",
    "        assign_valid_rows = np.where(fassign[\"TARGETID\"] >= 0)[0]\n",
    "        assign_tgids = np.sort(fassign[\"TARGETID\"][assign_valid_rows])\n",
    "        assign_target_rows = np.where(\n",
    "            np.isin(ftarget[\"TARGETID\"], assign_tgids)\n",
    "        )[0]\n",
    "        \n",
    "        # The available target IDs\n",
    "        avail_tgids = np.sort(np.unique(favail[\"TARGETID\"]))\n",
    "        avail_target_rows = np.where(\n",
    "            np.isin(ftarget[\"TARGETID\"], avail_tgids)\n",
    "        )[0]\n",
    "        \n",
    "        # For the science classes, we must also look at the obs remaining\n",
    "        # in order to know which targets were actually considered for assignment\n",
    "        # (not just reachable).\n",
    "        \n",
    "        for tgclass, mask in class_masks.items():\n",
    "            # The assigned targets in this class\n",
    "            assign_class_rows = assign_target_rows[\n",
    "                np.where(\n",
    "                    np.bitwise_and(\n",
    "                        ftarget[\"DESI_TARGET\"][assign_target_rows],\n",
    "                        mask\n",
    "                    )\n",
    "                )[0]\n",
    "            ]\n",
    "            if tgclass == \"QSO-lyman\":\n",
    "                assign_class_rows = assign_class_rows[\n",
    "                    np.where(\n",
    "                        np.isin(\n",
    "                            ftarget[\"TARGETID\"][assign_class_rows], qso_lyman\n",
    "                        )\n",
    "                    )[0]\n",
    "                ]\n",
    "            elif tgclass == \"QSO-tracer\":\n",
    "                assign_class_rows = assign_class_rows[\n",
    "                    np.where(\n",
    "                        np.isin(\n",
    "                            ftarget[\"TARGETID\"][assign_class_rows], qso_tracer\n",
    "                        )\n",
    "                    )[0]\n",
    "                ]\n",
    "            \n",
    "            hist_tgassign[tgclass].append(len(assign_class_rows))\n",
    "                \n",
    "            # The available targets in this class\n",
    "            avail_class_rows = avail_target_rows[\n",
    "                np.where(\n",
    "                    np.bitwise_and(\n",
    "                        ftarget[\"DESI_TARGET\"][avail_target_rows],\n",
    "                        mask\n",
    "                    )\n",
    "                )[0]\n",
    "            ]\n",
    "            if tgclass == \"QSO-lyman\":\n",
    "                avail_class_rows = avail_class_rows[\n",
    "                    np.where(\n",
    "                        np.isin(\n",
    "                            ftarget[\"TARGETID\"][avail_class_rows], qso_lyman\n",
    "                        )\n",
    "                    )[0]\n",
    "                ]\n",
    "            elif tgclass == \"QSO-tracer\":\n",
    "                avail_class_rows = avail_class_rows[\n",
    "                    np.where(\n",
    "                        np.isin(\n",
    "                            ftarget[\"TARGETID\"][avail_class_rows], qso_tracer\n",
    "                        )\n",
    "                    )[0]\n",
    "                ]\n",
    "\n",
    "            hist_tgavail[tgclass].append(len(avail_class_rows))\n",
    "            \n",
    "            #print(\"  target class {}, {} assignments\".format(tgclass, len(assign_class_rows)))\n",
    "            \n",
    "            if tgclass == \"STD\" or tgclass == \"SKY\":\n",
    "                # the considered targets are the same as the reachable\n",
    "                hist_tgconsid[tgclass].append(len(avail_class_rows))\n",
    "                hist_tgfrac[tgclass].append(len(assign_class_rows) / len(avail_class_rows))\n",
    "            else:\n",
    "                # compare to obs remaining\n",
    "                hist_tgconsid[tgclass].append(\n",
    "                    np.sum(\n",
    "                        [1 for x in ftarget[\"TARGETID\"][avail_class_rows] if obs[x] > 0]\n",
    "                    )\n",
    "                )\n",
    "                hist_tgfrac[tgclass].append(len(assign_class_rows) / hist_tgconsid[tgclass][-1])\n",
    "\n",
    "                # Now reduce the obs remaining\n",
    "                for tgid in ftarget[\"TARGETID\"][assign_class_rows]:\n",
    "                    obs[tgid] -= 1\n",
    "    \n",
    "    # Return our histogram of tile data and also the updated observation counts,\n",
    "    # which can be used to update the MTL NUMOBS_MORE in a separate function.\n",
    "    return (obs, hist_tgassign, hist_tgavail, hist_tgconsid, hist_tgfrac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the accumulated assignment counts from a set of tiles.  This is \n",
    "# designed to run on the results from one pass / layer.  If you plot the results from\n",
    "# multiple layers, it will broaden all the distributions, since the considered and assigned\n",
    "# targets will go down as the survey progresses.\n",
    "\n",
    "def plot_assignment_stats(\n",
    "        wd, outname, title,\n",
    "        hist_tgassign, hist_tgavail, hist_tgconsid, hist_tgfrac\n",
    "):\n",
    "    classes = list(sorted(hist_tgavail.keys()))\n",
    "    fiberbins = 0.01 * np.arange(101)\n",
    "    tgbins = {\n",
    "        \"ELG\": np.arange(0, 22220, 220),\n",
    "        \"LRG\": np.arange(0, 4040, 40),\n",
    "        \"QSO-tracer\": np.arange(0, 2424, 24),\n",
    "        \"QSO\": np.arange(0, 2424, 24),\n",
    "        \"QSO-lyman\": np.arange(0, 808, 8),\n",
    "        \"STD\": np.arange(0, 1212, 12),\n",
    "        \"SKY\": np.arange(0, 40400, 400)\n",
    "    }\n",
    "\n",
    "    # The plots\n",
    "    figfiber = plt.figure(figsize=(12, 6))\n",
    "    figtarget = plt.figure(figsize=(12, 18))\n",
    "\n",
    "    # Plot the positioner assignment fractions\n",
    "    axfiber = figfiber.add_subplot(1, 1, 1)\n",
    "\n",
    "    for tgclass in classes:\n",
    "        if np.sum(hist_tgassign[tgclass]) > 0:\n",
    "            axfiber.hist(\n",
    "                np.array(hist_tgassign[tgclass]) / 5000, \n",
    "                fiberbins, \n",
    "                align=\"mid\", \n",
    "                alpha=0.8, \n",
    "                label=\"{}\".format(tgclass),\n",
    "                color=target_pltcolor[tgclass]\n",
    "            )\n",
    "    axfiber.set_xlabel(\"Fraction of Assigned Positioners\", fontsize=\"large\")\n",
    "    axfiber.set_ylabel(\"Tile Counts\", fontsize=\"large\")\n",
    "    axfiber.set_ylim(0, 50)\n",
    "    axfiber.set_title(\n",
    "        \"Positioner Assignment : {}\".format(title)\n",
    "    )\n",
    "    axfiber.legend()\n",
    "    figfiber.savefig(\n",
    "        os.path.join(wd, \"fiberassign_{}_fibers.pdf\".format(outname)),\n",
    "        dpi=300, \n",
    "        format=\"pdf\"\n",
    "    )\n",
    "    figfiber.show()\n",
    "\n",
    "    prows = len(classes)\n",
    "    pcols = 2\n",
    "    poff = 1\n",
    "    for tgclass in classes:\n",
    "        if np.sum(hist_tgavail[tgclass]) == 0:\n",
    "            continue\n",
    "        # First the assignment / considered / available plot\n",
    "        axtarget = figtarget.add_subplot(prows, pcols, poff)\n",
    "        axtarget.hist(\n",
    "            np.array(hist_tgavail[tgclass]), \n",
    "            tgbins[tgclass], \n",
    "            align=\"mid\", \n",
    "            alpha=0.4, \n",
    "            label=\"{} Reachable\".format(tgclass),\n",
    "            color=(0.7, 0.7, 0.7)\n",
    "        )\n",
    "        axtarget.hist(\n",
    "            np.array(hist_tgconsid[tgclass]), \n",
    "            tgbins[tgclass], \n",
    "            align=\"mid\", \n",
    "            alpha=0.4, \n",
    "            label=\"{} Considered\".format(tgclass),\n",
    "            color=target_pltcolor[tgclass]\n",
    "        )\n",
    "        axtarget.hist(\n",
    "            np.array(hist_tgassign[tgclass]), \n",
    "            tgbins[tgclass], \n",
    "            align=\"mid\", \n",
    "            alpha=0.8, \n",
    "            label=\"{} Assigned\".format(tgclass),\n",
    "            color=target_pltcolor[tgclass]\n",
    "        )\n",
    "        axtarget.set_xlabel(\"Targets Reachable, Considered, and Assigned\", fontsize=\"large\")\n",
    "        axtarget.set_ylabel(\"Tile Counts\", fontsize=\"large\")\n",
    "        axtarget.set_ylim(0, 50)\n",
    "        axtarget.legend()\n",
    "        poff += 1\n",
    "        \n",
    "        # Now the assignment fraction\n",
    "        axtarget = figtarget.add_subplot(prows, pcols, poff)\n",
    "        axtarget.hist(\n",
    "            np.array(hist_tgfrac[tgclass]), \n",
    "            fiberbins, \n",
    "            align=\"mid\", \n",
    "            alpha=0.8, \n",
    "            label=\"Fraction of Considered {} Assigned\".format(tgclass),\n",
    "            color=target_pltcolor[tgclass]\n",
    "        )\n",
    "        axtarget.set_xlabel(\"Fraction of Considered Targets that were Assigned\", fontsize=\"large\")\n",
    "        axtarget.set_ylabel(\"Tile Counts\", fontsize=\"large\")\n",
    "        axtarget.set_ylim(0, 50)\n",
    "        axtarget.legend()\n",
    "        \n",
    "        poff += 1\n",
    "\n",
    "    figtarget.suptitle(\n",
    "        \"{}\".format(title), fontsize=\"x-large\"\n",
    "    )\n",
    "    figtarget.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    figtarget.savefig(\n",
    "        os.path.join(wd, \"fiberassign_{}_targets.pdf\".format(outname)),\n",
    "        dpi=300, \n",
    "        format=\"pdf\"\n",
    "    )\n",
    "    figtarget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_qso_lyman(input_mtl, output_mtl, density, original_mtl, effective_mtl):\n",
    "    # Set the random seed to ensure reproducibility of this cell\n",
    "    np.random.seed(123456)\n",
    "\n",
    "    # Load the input MTL\n",
    "    print(\"Loading data from {}\".format(input_mtl), flush=True)\n",
    "    mtldata = None\n",
    "    with fitsio.FITS(input_mtl) as fd:\n",
    "        mtldata = fd[1].read()\n",
    "    \n",
    "    # The rows with all QSOs was computed globally during the initial MTL creation...\n",
    "    \n",
    "    # Find the QSOs we just observed\n",
    "    qso_observed_rows = np.where(\n",
    "        np.logical_and(\n",
    "            np.bitwise_and(\n",
    "                mtldata[\"DESI_TARGET\"],\n",
    "                desi_mask[\"QSO\"].mask\n",
    "            ),\n",
    "            (mtldata[\"NUMOBS_MORE\"] == 3)\n",
    "        )\n",
    "    )[0]\n",
    "    \n",
    "    print(\"  {} total QSO rows\".format(len(qso_rows)))\n",
    "    print(\"  {} observed QSOs in first pass\".format(len(qso_observed_rows)))\n",
    "    \n",
    "    # Select a subset of these targets at the correct density.  There are many ways we could\n",
    "    # do this.  For this exercise we will use an approximate method:\n",
    "    #\n",
    "    #    1. Take an inner region of the footprint and compute the target density\n",
    "    #       of the just-observed QSOs.\n",
    "    #\n",
    "    #    2. Take the ratio of the desired density to this value.\n",
    "    #\n",
    "    #    3. Use the ratio to get a total number of targets to select from the input.\n",
    "    #\n",
    "    #    4. Uniformly sample RA / DEC points and choose nearby objects until we reach\n",
    "    #       our desired total selection.\n",
    "    #\n",
    "    \n",
    "    # Inner RA/DEC range\n",
    "    inner_ra_min = target_ra_min + 7.0\n",
    "    inner_ra_max = target_ra_max - 7.0\n",
    "    inner_dec_min = target_dec_min + 7.0\n",
    "    inner_dec_max = target_dec_max - 7.0\n",
    "    \n",
    "    inner = np.where(\n",
    "        np.logical_and(\n",
    "            np.logical_and(\n",
    "                (mtldata[\"RA\"][qso_observed_rows] > inner_ra_min), \n",
    "                (mtldata[\"RA\"][qso_observed_rows] < inner_ra_max)\n",
    "            ), np.logical_and(\n",
    "                (mtldata[\"DEC\"][qso_observed_rows] > inner_dec_min), \n",
    "                (mtldata[\"DEC\"][qso_observed_rows] < inner_dec_max)\n",
    "            )\n",
    "        )\n",
    "    )[0]\n",
    "    \n",
    "    qso_observed_density = len(inner) / ((inner_ra_max - inner_ra_min) * (inner_dec_max - inner_dec_min))\n",
    "    \n",
    "    n_select = int(len(qso_observed_rows) * (density / qso_observed_density))\n",
    "    \n",
    "    print(\"  Selecting {} random QSOs\".format(n_select))\n",
    "    \n",
    "    # Create a KDTree of the QSOs\n",
    "    \n",
    "    kqso = KDTree(\n",
    "        np.array(list(zip(\n",
    "            mtldata[\"RA\"][qso_observed_rows], \n",
    "            mtldata[\"DEC\"][qso_observed_rows]\n",
    "        )))\n",
    "    )\n",
    "    \n",
    "    selected = list()\n",
    "    n_cur = 0\n",
    "    while n_cur < n_select:\n",
    "        buf = 10000\n",
    "        print(\"  Working on random selection at {} of {} required...\".format(n_cur, n_select))\n",
    "        test_ra = np.random.uniform(low=target_ra_min, high=target_ra_max, size=buf)\n",
    "        test_dec = np.random.uniform(low=target_dec_min, high=target_dec_max, size=buf)\n",
    "        dist, indx = kqso.query(np.array(list(zip(test_ra, test_dec))), k=1)\n",
    "        for i in range(buf):\n",
    "            if indx[i] in selected:\n",
    "                continue\n",
    "            selected.append(indx[i])\n",
    "            n_cur += 1\n",
    "            if n_cur == n_select:\n",
    "                break\n",
    "    \n",
    "    selected_rows = np.array(sorted(selected))\n",
    "    qso_selected_rows = qso_observed_rows[selected_rows]\n",
    "    \n",
    "    not_selected_mask = np.ones(len(mtldata), dtype=np.bool)\n",
    "    not_selected_mask[:] = False\n",
    "    not_selected_mask[qso_rows] = True\n",
    "    not_selected_mask[qso_selected_rows] = False\n",
    "    \n",
    "    qso_not_selected_rows = np.where(not_selected_mask)[0]\n",
    "    \n",
    "    print(\"  {} QSO-lyman targets\".format(len(qso_selected_rows)))\n",
    "    print(\"  {} QSO-tracer targets\".format(len(qso_not_selected_rows)))\n",
    "    \n",
    "    # Plot the selection\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    ax.scatter(\n",
    "        mtldata[\"RA\"][qso_observed_rows], \n",
    "        mtldata[\"DEC\"][qso_observed_rows], \n",
    "        s=1, c=(0.6, 0.6, 0.6), marker=\".\",\n",
    "        label=\"QSO Observed\"\n",
    "    )\n",
    "    \n",
    "    ax.scatter(\n",
    "        mtldata[\"RA\"][qso_selected_rows], \n",
    "        mtldata[\"DEC\"][qso_selected_rows], \n",
    "        s=1, c=\"red\", marker=\".\",\n",
    "        label=\"QSO Selected\"\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel(\"RA\", fontsize=\"large\")\n",
    "    ax.set_ylabel(\"DEC\", fontsize=\"large\")\n",
    "    ax.set_title(\"QSOs Observed in Pass 1\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Set the observations remaining for all other \"tracer\" QSOs.  For objects\n",
    "    # that we already observed, these are done.  Other objects will have one observation\n",
    "    # requested.\n",
    "    \n",
    "    mtldata[\"NUMOBS_MORE\"][qso_not_selected_rows] -= 3\n",
    "    \n",
    "    # Write new file\n",
    "    if os.path.isfile(output_mtl):\n",
    "        os.remove(output_mtl)\n",
    "\n",
    "    print(\"Writing updated MTL to {}\".format(output_mtl), flush=True)\n",
    "    with fitsio.FITS(output_mtl, \"rw\") as fd:\n",
    "        fd.write(mtldata)\n",
    "    del mtldata\n",
    "    \n",
    "    # In order to get accurate counts based on the future differences between MTLs,\n",
    "    # we take the original MTL and retro-actively modify NUMOBS_INIT to match our\n",
    "    # QSO selection\n",
    "    \n",
    "    print(\"Loading original MTL from {}\".format(original_mtl), flush=True)\n",
    "    mtldata = None\n",
    "    with fitsio.FITS(original_mtl) as fd:\n",
    "        mtldata = fd[1].read()\n",
    "    \n",
    "    mtldata[\"NUMOBS_INIT\"][qso_not_selected_rows] -= 3\n",
    "    \n",
    "    print(\"Writing effective MTL to {}\".format(effective_mtl), flush=True)\n",
    "    if os.path.isfile(effective_mtl):\n",
    "        os.remove(effective_mtl)\n",
    "    with fitsio.FITS(effective_mtl, \"rw\") as fd:\n",
    "        fd.write(mtldata)\n",
    "    del mtldata\n",
    "    \n",
    "    return (qso_selected_rows, qso_not_selected_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Survey\n",
    "\n",
    "In our initial MTL files, all QSOs have 4 requested observations.  We will start by running the first pass / layer.  **Of the QSOs that receive an observation**, we will choose a subset of these (to make up a particular density) for further observations.  All other QSOs will have \"3\" subtracted from their remaining observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pass, using starting MTLs\n",
    "\n",
    "fiberassign_out = os.path.join(workdir, \"fiberassign_pass_1\") \n",
    "run_assignment(tilefile_pass[\"1\"], fiberassign_out, science_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate counts\n",
    "\n",
    "(obs, hist_assign, hist_avail, hist_consid, hist_frac) = assignment_counts(\n",
    "    tilefile_pass[\"1\"], science_file, fiberassign_out, list(), qso_rows\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "plot_assignment_stats(\n",
    "    workdir, \"pass_1\", \"Assignment for Pass 1\",\n",
    "    hist_assign, hist_avail, hist_consid, hist_frac\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update MTL\n",
    "\n",
    "mtl_after1 = os.path.join(workdir, \"{}_after_pass_1.fits\".format(science_file_root))\n",
    "update_mtl(science_file, mtl_after1, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of observations of each target class so far.  We have not selected QSOs for\n",
    "# Further observations yet, so all of the QSOs are \"tracers\" at the moment.\n",
    "\n",
    "obs_counts = diff_mtl(science_file, mtl_after1, list(), qso_rows)\n",
    "for tgclass, props in obs_counts.items():\n",
    "    print(\"{:10s} : {:7d} observations of {:7d} requested ({:0.1f}%)\".format(\n",
    "        tgclass, props[\"achieved\"], props[\"requested\"], 100*(props[\"achieved\"] / props[\"requested\"])\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have completed the first pass, we want to select which of the just-observed QSOs we will choose for further observations.  The QSOs which now have \"3\" remaining observations are the ones we just observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_after_qso = os.path.join(workdir, \"{}_after_QSO_select.fits\".format(science_file_root))\n",
    "effective_science_file = os.path.join(workdir, \"{}_effective.fits\".format(science_file_root))\n",
    "\n",
    "qso_lyman_rows, qso_tracer_rows = select_qso_lyman(\n",
    "    mtl_after1, \n",
    "    mtl_after_qso, \n",
    "    60.0,\n",
    "    science_file,\n",
    "    effective_science_file\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passes 2 - 4\n",
    "\n",
    "Now we can loop over our passes / layers and assign each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_output = mtl_after_qso\n",
    "\n",
    "for survey_pass in [\"2\", \"3\", \"4\"]:\n",
    "    print(\"Working on Survey Pass {}\".format(survey_pass), flush=True)\n",
    "    mtl_input = mtl_output\n",
    "    \n",
    "    fiberassign_out = os.path.join(workdir, \"fiberassign_pass_{}\".format(survey_pass)) \n",
    "    run_assignment(tilefile_pass[survey_pass], fiberassign_out, mtl_input)\n",
    "    \n",
    "    (obs, hist_assign, hist_avail, hist_consid, hist_frac) = assignment_counts(\n",
    "        tilefile_pass[survey_pass], \n",
    "        mtl_input, \n",
    "        fiberassign_out,\n",
    "        qso_lyman_rows, \n",
    "        qso_tracer_rows\n",
    "    )\n",
    "    \n",
    "    plot_assignment_stats(\n",
    "        workdir, \n",
    "        \"pass_{}\".format(survey_pass), \n",
    "        \"Assignment for Pass {}\".format(survey_pass),\n",
    "        hist_assign, hist_avail, hist_consid, hist_frac\n",
    "    )\n",
    "    \n",
    "    mtl_output = os.path.join(workdir, \"{}_after_pass_{}.fits\".format(science_file_root, survey_pass))\n",
    "    update_mtl(mtl_input, mtl_output, obs)\n",
    "    \n",
    "    obs_counts = diff_mtl(effective_science_file, mtl_output, qso_lyman_rows, qso_tracer_rows)\n",
    "    for tgclass, props in obs_counts.items():\n",
    "        print(\"{:10s} : {:7d} observations of {:7d} requested ({:0.1f}%)\".format(\n",
    "            tgclass, props[\"achieved\"], props[\"requested\"], 100*(props[\"achieved\"] / props[\"requested\"])\n",
    "        ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESI 20.8",
   "language": "python",
   "name": "desi-20.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
